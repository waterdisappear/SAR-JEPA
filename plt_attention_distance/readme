Here is the python code for our Figure 6. The averaged attention distance of ViT using various methods. The X-axis is the attention head, that is, the layer number. Attention distance is computed based on example pictures by averaging the distance between the query pixel and all other pixels, weighted by the attention weight. A larger attention distance indicates the ability to focus on the correlation of two more distant pixels in an image.} MAE focuses on global information, and other methods focus on local and global attention ranges. This shows that using pixel-level features as a pretext task with a local image scale can enhance the diversity of Vit modeling with SAR images.
